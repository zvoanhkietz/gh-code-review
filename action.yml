name: 'Code Review using Ollama'
description: 'Perform a code review on code modified using Ollama'
inputs:
  llm-model:
    description: 'Name of the LLM model to use for code review'
    required: true
    default: 'codegemma'
runs:
  using: 'composite'
  steps:
      - name: Checkout Repository
        uses: actions/checkout@v2

      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | bash
          ollama pull codegemma
        shell: bash

      - name: Start Ollama Service
        run: |
          nohup ollama &>/dev/null &
          sleep 10  # Wait for the service to start
        shell: bash

      - name: Verify Ollama Service
        run: |
          if ! curl -s http://127.0.0.1:11434/api/status; then
            echo "Ollama service is not running"
            exit 1
          fi
        shell: bash
